# Conditional Model Selection Pipeline
# Selects model based on data size, using EXTERNAL experiment configs
#
# Flow: load_data → preprocess → branch[TFT | XGBoost] → evaluate → log
#
# Each branch loads FULL config from separate experiment YAML files.
# This allows complete customization of model, hyperparams, data settings.

pipeline:
  name: "conditional_model_selection_eval"

  steps:
    # Stage 1: Data Loading
    - id: "load_data"
      type: "data_loader"
      enabled: true

    - id: "init_artifacts"
      type: "mlflow_loader"
      enabled: true
      alias: "latest"
      load_map:
        - { step_id: "preprocess", context_key: "fitted_preprocess" }
        - { step_id: "train_tft", context_key: "fitted_train_tft" }
        - { step_id: "train_xgb", context_key: "fitted_train_xgb" }
    # Stage 2: Preprocessing
    - id: "preprocess"
      type: "preprocessor"
      enabled: true
      depends_on: ["load_data"]
      instance_key: "fitted_preprocess"
      is_train: false  # Important: loads fitted state from context instead of refitting

    # Stage 3: Conditional Model Selection
    - id: "model_selection"
      type: "branch"
      enabled: true
      depends_on: ["preprocess"]
      condition:
        key: "data_size"
        operator: ">"
        value: 100

      # Execute if data_size > 100 → Load TFT config from external file
      if_true:
        id: "tft_evaluate"
        type: "evaluator"
        enabled: true
        depends_on: ["preprocess"]
        wiring:
          inputs:
            model: "fitted_train_tft"
            features: "preprocessed_data"
            targets: "target_data"
          outputs:
            metrics: "evaluation_metrics"

      # Execute if data_size <= 100 → Load XGBoost config from external file
      if_false:
        id: "xgboost_evaluate"
        type: "evaluator"
        enabled: true
        depends_on: ["preprocess"]
        wiring:
          inputs:
            model: "fitted_train_xgb"
            features: "preprocessed_data"
            targets: "target_data"
          outputs:
            metrics: "evaluation_metrics"

    # Stage 5: Log Results
    - id: "log_results"
      type: "logger"
      enabled: true
      depends_on: ["model_selection"]

pipeline:
  name: "standard_train"
  description: "Training pipeline with profiling: load -> preprocess -> train -> evaluate -> profile -> log"

  steps:
    # Step 1: Load data from source
    - id: "load_data"
      type: "data_loader"
      enabled: true

    # Step 2: Preprocessing - fit and transform data
    - id: "preprocess"
      type: "preprocessor"
      enabled: true
      log_artifact: true
      artifact_type: "preprocess"
      depends_on: ["load_data"]
      is_train: true

    - id: "prepare_data"
      type: "datamodule"
      depends_on: ["preprocess"]
      wiring:
        inputs:
          features: "preprocessed_data"
          targets: "target_data"
        outputs: { datamodule: "prepare_data_datamodule" }

    - id: "train_model"
      type: "trainer"
      depends_on: ["prepare_data"]
      log_artifact: true
      artifact_type: "model"
      wiring:
        inputs: { datamodule: "prepare_data_datamodule" }
        outputs: { model: "train_model_model" }

    # Step 4: Evaluate model
    - id: "evaluate"
      type: "evaluator"
      enabled: true
      depends_on: ["train_model"]
      wiring:
        inputs:
          # Load model instance from the trainer step
          model: "train_model_model"
          # Load DataModule from the data preparation step instead of rebuilding it
          datamodule: "prepare_data_datamodule"
        outputs:
          metrics: "evaluation_metrics"

    # Step 5: Profile outputs (NEW)
    - id: "profiling"
      type: "profiling"
      enabled: true
      depends_on: ["evaluate"]
      exclude_keys: ["cfg", "preprocessor", "df", "train_df", "val_df"]

    # Step 6: Log to MLflow (includes config artifacts)
    - id: "log_results"
      type: "logger"
      enabled: true
      depends_on: ["train_model", "evaluate", "profiling"]

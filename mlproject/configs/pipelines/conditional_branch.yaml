# Conditional Model Selection Pipeline
# Selects model based on data size
#
# Flow: load_data → preprocess → branch[TFT | XGBoost] → evaluate → log
#
# - If data_size > 10000: Use TFT (deep learning)
# - Else: Use XGBoost (gradient boosting)

pipeline:
  name: "conditional_model_selection"

  steps:
    # Stage 1: Data Loading
    # DataLoaderStep automatically sets context["data_size"] = len(df)
    - id: "load_data"
      type: "data_loader"
      enabled: true

    # Stage 2: Preprocessing
    - id: "preprocess"
      type: "preprocessor"
      enabled: true
      depends_on: ["load_data"]
      is_train: true

    # Stage 3: Conditional Model Selection
    - id: "model_selection"
      type: "branch"
      enabled: true
      depends_on: ["preprocess"]
      condition:
        key: "data_size"
        operator: ">"
        value: 10000

      # Execute if data_size > 10000 (large dataset)
      if_true:
        id: "train_tft"
        type: "trainer"
        wiring:
          inputs:
            data: "preprocessed_data"
          outputs:
            model: "selected_model"
            datamodule: "selected_dm"

      # Execute if data_size <= 10000 (small dataset)
      if_false:
        id: "train_xgb"
        type: "trainer"
        wiring:
          inputs:
            data: "preprocessed_data"
          outputs:
            model: "selected_model"
            datamodule: "selected_dm"

    # Stage 4: Evaluation (works with either model)
    - id: "evaluate"
      type: "evaluator"
      enabled: true
      depends_on: ["model_selection"]
      wiring:
        inputs:
          model: "selected_model"
          datamodule: "selected_dm"
        outputs:
          metrics: "evaluation_metrics"

    # Stage 5: Log Results
    - id: "log_results"
      type: "logger"
      enabled: true
      depends_on: ["evaluate"]
      wiring:
        inputs:
          model: "selected_model"
          metrics: "evaluation_metrics"

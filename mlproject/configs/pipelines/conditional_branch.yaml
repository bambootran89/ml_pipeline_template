# Conditional Model Selection Pipeline
# Selects model based on data size, using EXTERNAL experiment configs
#
# Flow: load_data → preprocess → branch[TFT | XGBoost] → evaluate → log
#
# Each branch loads FULL config from separate experiment YAML files.
# This allows complete customization of model, hyperparams, data settings.

pipeline:
  name: "conditional_model_selection"

  steps:
    # Stage 1: Data Loading
    - id: "load_data"
      type: "data_loader"
      enabled: true

    # Stage 2: Preprocessing
    - id: "preprocess"
      type: "preprocessor"
      enabled: true
      depends_on: ["load_data"]
      is_train: true

    # Stage 3: Conditional Model Selection
    - id: "model_selection"
      type: "branch"
      enabled: true
      depends_on: ["preprocess"]
      condition:
        key: "data_size"
        operator: ">"
        value: 100

      # Execute if data_size > 100 → Load TFT config from external file
      if_true:
        id: "train_tft"
        type: "generic_model"
        experiment_config: "mlproject/configs/model/tft_ts.yaml"
        wiring:
          inputs:
            data: "preprocessed_data"
          outputs:
            model: "selected_model"
            datamodule: "selected_dm"

      # Execute if data_size <= 100 → Load XGBoost config from external file
      if_false:
        id: "train_xgb"
        type: "generic_model"
        experiment_config: "mlproject/configs/model/xgboost_ts.yaml"
        wiring:
          inputs:
            data: "preprocessed_data"
          outputs:
            model: "selected_model"
            datamodule: "selected_dm"

    # Stage 4: Evaluation
    - id: "evaluate"
      type: "evaluator"
      enabled: true
      depends_on: ["model_selection"]
      wiring:
        inputs:
          model: "selected_model"
          datamodule: "selected_dm"
        outputs:
          metrics: "evaluation_metrics"

    # Stage 5: Log Results
    - id: "log_results"
      type: "logger"
      enabled: true
      depends_on: ["evaluate"]
      wiring:
        inputs:
          model: "selected_model"
          metrics: "evaluation_metrics"

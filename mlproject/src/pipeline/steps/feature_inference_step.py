"""Feature inference step for eval/serve modes."""

from __future__ import annotations

from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd
from omegaconf import OmegaConf

from mlproject.src.pipeline.steps.base import BasePipelineStep
from mlproject.src.pipeline.steps.factory_step import StepFactory


class FeatureInferenceStep(BasePipelineStep):
    """Generate features from loaded model in eval/serve mode.

    This step is auto-generated by ConfigGenerator for eval/serve
    pipelines when feature_pipeline is declared in train config.

    It handles:
    1. Loading base features from context
    2. Using loaded model to generate features
    3. Storing features in specified output_key

    This eliminates manual inference step creation and ensures
    consistency between train/eval/serve pipelines.
    """

    def __init__(
        self,
        step_id: str,
        cfg: Any,
        enabled: bool = True,
        depends_on: Optional[List[str]] = None,
        source_model_key: str = "model",
        base_features_key: str = "preprocessed_data",
        output_key: str = "features",
        experiment_config: Optional[Any] = None,
        inference_method: str = "predict",
        apply_windowing: bool = True,
        **kwargs: Any,
    ) -> None:
        """Initialize feature inference step."""
        super().__init__(step_id, cfg, enabled, depends_on, **kwargs)
        self.source_model_key = source_model_key
        self.base_features_key = base_features_key
        self.output_key = output_key
        self.inference_method = inference_method
        self.apply_windowing = apply_windowing

        # Merge experiment config to access global settings (e.g. data type, chunks)
        if experiment_config is None:
            self.effective_cfg = cfg
        else:
            self.effective_cfg = OmegaConf.merge(cfg, experiment_config)

    def _get_model_and_input(self, context: Dict[str, Any]) -> tuple[Any, np.ndarray]:
        """Get model and prepared input from context."""
        model = context.get(self.source_model_key)
        if model is None:
            raise KeyError(
                f"Step '{self.step_id}': Model key "
                f"'{self.source_model_key}' not found in context"
            )

        base_features = context.get(self.base_features_key)
        if base_features is None:
            raise KeyError(
                f"Step '{self.step_id}': Base features key "
                f"'{self.base_features_key}' not found in context"
            )

        return model, self._prepare_input(base_features)

    def _run_windowed_inference(
        self, model: Any, x: np.ndarray, method_name: str
    ) -> np.ndarray:
        """Run inference with windowing."""
        hyperparams = self.effective_cfg.get("experiment", {}).get("hyperparams", {})
        input_chunk = hyperparams.get("input_chunk_length", 1)
        output_chunk = hyperparams.get("output_chunk_length", 1)

        x_windows = self._create_windows(x, input_chunk, output_chunk)
        print(f"  Windowed shape: {x_windows.shape}")

        model_type_value = getattr(model, "model_type", None)
        is_dl_model = model_type_value in ["dl", "timeseries", "multivariate"]

        if not is_dl_model and x_windows.ndim == 3:
            x_windows = x_windows.reshape(x_windows.shape[0], -1)

        inference_func = getattr(model, method_name)
        features = inference_func(x_windows)

        if features.ndim == 3:
            features = features.reshape(features.shape[0], -1)

        return features

    def execute(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute feature generation."""
        self.validate_dependencies(context)

        model, x = self._get_model_and_input(context)

        data_cfg = self.effective_cfg.get("data", {})
        data_type = str(data_cfg.get("type", "tabular")).lower()

        method_name = self.inference_method
        if not hasattr(model, method_name):
            if method_name == "predict" and hasattr(model, "transform"):
                print(
                    f"[{self.step_id}] Model missing 'predict', "
                    "falling back to 'transform'"
                )
                method_name = "transform"
            else:
                raise AttributeError(
                    f"Step '{self.step_id}': Model '{self.source_model_key}' "
                    f"has no method '{method_name}'"
                )

        print(
            f"[{self.step_id}] Generating features from "
            f"'{self.source_model_key}' using '{method_name}'"
        )
        print(f"  Input shape: {x.shape}")

        if data_type == "timeseries" and self.apply_windowing:
            features = self._run_windowed_inference(model, x, method_name)
        else:
            inference_func = getattr(model, method_name)
            features = inference_func(x)

        # Store in context
        context[self.output_key] = features
        print(
            f"[{self.step_id}] Stored features in '{self.output_key}' "
            f"(shape: {features.shape})"
        )

        return context

    def _create_windows(
        self, x: np.ndarray, input_chunk: int, output_chunk: int
    ) -> np.ndarray:
        """Create sliding windows from input array."""
        n = len(x)
        windows = []
        stride = 1

        # Logic matching BaseDataModule._create_windows
        for end_idx in range(input_chunk, n - output_chunk + 1, stride):
            start_idx = end_idx - input_chunk
            # Do NOT flatten window -> keep (Time, Feat)
            win = x[start_idx:end_idx]
            windows.append(win)

        if not windows:
            return np.empty((0, input_chunk, x.shape[1]))

        return np.stack(windows)

    def _prepare_input(self, features: Any) -> np.ndarray:
        """Prepare input for model prediction.

        Parameters
        ----------
        features : Any
            Raw features (DataFrame, ndarray, etc).

        Returns
        -------
        np.ndarray
            Prepared input array.
        """

        if isinstance(features, pd.DataFrame):
            return features.values.astype(np.float64)

        if isinstance(features, np.ndarray):
            return features.astype(np.float64)

        if isinstance(features, (list, tuple)):
            return np.array(features, dtype=np.float64)

        raise TypeError(f"Unsupported feature type: {type(features).__name__}")


StepFactory.register("feature_inference", FeatureInferenceStep)
